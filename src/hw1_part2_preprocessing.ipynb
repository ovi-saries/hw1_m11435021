{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a66793e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Unified Data Preprocessor Usage Example\n",
      "============================================================\n",
      "\n",
      "\n",
      "[Example 1] CART model usage (no discretization, no validation set)\n",
      "------------------------------------------------------------\n",
      "============================================================\n",
      "Loading raw data\n",
      "============================================================\n",
      "Training data shape: (32561, 15)\n",
      "Test data shape: (16281, 15)\n",
      "\n",
      "Cleaning data...\n",
      "Training data: 32561 → 30162 (removed 2399 rows)\n",
      "Test data: 16281 → 15060 (removed 1221 rows)\n",
      "\n",
      "Encoding categorical features...\n",
      "✓ Encoding complete for 8 categorical features\n",
      "\n",
      "============================================================\n",
      "Data preparation complete\n",
      "============================================================\n",
      "Number of features: 14\n",
      "  - Continuous features: 6\n",
      "  - Categorical features: 8\n",
      "Discretized: False\n",
      "\n",
      "Data shapes:\n",
      "  Training set: (30162, 14)\n",
      "  Test set: (15060, 14)\n",
      "\n",
      "Label distribution (>50K proportion):\n",
      "  Training set: 24.89%\n",
      "  Test set: 24.57%\n",
      "============================================================\n",
      "\n",
      "CART can use directly:\n",
      "  X_train: (30162, 14), y_train: (30162,)\n",
      "  X_test: (15060, 14), y_test: (15060,)\n",
      "\n",
      "[Example 2] C4.5 model usage (no discretization, with validation set)\n",
      "------------------------------------------------------------\n",
      "============================================================\n",
      "Loading raw data\n",
      "============================================================\n",
      "Training data shape: (32561, 15)\n",
      "Test data shape: (16281, 15)\n",
      "\n",
      "Cleaning data...\n",
      "Training data: 32561 → 30162 (removed 2399 rows)\n",
      "Test data: 16281 → 15060 (removed 1221 rows)\n",
      "\n",
      "Encoding categorical features...\n",
      "✓ Encoding complete for 8 categorical features\n",
      "\n",
      "============================================================\n",
      "Data preparation complete\n",
      "============================================================\n",
      "Number of features: 14\n",
      "  - Continuous features: 6\n",
      "  - Categorical features: 8\n",
      "Discretized: False\n",
      "\n",
      "Data split:\n",
      "  Training set: (27145, 14)\n",
      "  Validation set: (3017, 14)\n",
      "  Test set: (15060, 14)\n",
      "\n",
      "Label distribution (>50K proportion):\n",
      "  Training set: 24.89%\n",
      "  Validation set: 24.89%\n",
      "  Test set: 24.57%\n",
      "============================================================\n",
      "\n",
      "C4.5 can use directly:\n",
      "  Training set: (27145, 14)\n",
      "  Validation set: (3017, 14)\n",
      "  Test set: (15060, 14)\n",
      "\n",
      "[Example 3] ID3 model usage (with discretization, with validation set)\n",
      "------------------------------------------------------------\n",
      "============================================================\n",
      "Loading raw data\n",
      "============================================================\n",
      "Training data shape: (32561, 15)\n",
      "Test data shape: (16281, 15)\n",
      "\n",
      "Cleaning data...\n",
      "Training data: 32561 → 30162 (removed 2399 rows)\n",
      "Test data: 16281 → 15060 (removed 1221 rows)\n",
      "\n",
      "Encoding categorical features...\n",
      "✓ Encoding complete for 8 categorical features\n",
      "\n",
      "Discretizing continuous features (n_bins=10)...\n",
      "✓ Discretization complete, each feature divided into 10 bins\n",
      "\n",
      "============================================================\n",
      "Data preparation complete\n",
      "============================================================\n",
      "Number of features: 14\n",
      "  - Continuous features: 6\n",
      "  - Categorical features: 8\n",
      "Discretized: True\n",
      "\n",
      "Data split:\n",
      "  Training set: (24129, 14)\n",
      "  Validation set: (6033, 14)\n",
      "  Test set: (15060, 14)\n",
      "\n",
      "Label distribution (>50K proportion):\n",
      "  Training set: 24.89%\n",
      "  Validation set: 24.90%\n",
      "  Test set: 24.57%\n",
      "============================================================\n",
      "\n",
      "ID3 can use directly:\n",
      "  Training set: (24129, 14)\n",
      "  Validation set: (6033, 14)\n",
      "  Test set: (15060, 14)\n",
      "\n",
      "[Example 4] C5.0 model usage (with discretization, with validation set)\n",
      "------------------------------------------------------------\n",
      "============================================================\n",
      "Loading raw data\n",
      "============================================================\n",
      "Training data shape: (32561, 15)\n",
      "Test data shape: (16281, 15)\n",
      "\n",
      "Cleaning data...\n",
      "Training data: 32561 → 30162 (removed 2399 rows)\n",
      "Test data: 16281 → 15060 (removed 1221 rows)\n",
      "\n",
      "Encoding categorical features...\n",
      "✓ Encoding complete for 8 categorical features\n",
      "\n",
      "Discretizing continuous features (n_bins=10)...\n",
      "✓ Discretization complete, each feature divided into 10 bins\n",
      "\n",
      "============================================================\n",
      "Data preparation complete\n",
      "============================================================\n",
      "Number of features: 14\n",
      "  - Continuous features: 6\n",
      "  - Categorical features: 8\n",
      "Discretized: True\n",
      "\n",
      "Data split:\n",
      "  Training set: (24129, 14)\n",
      "  Validation set: (6033, 14)\n",
      "  Test set: (15060, 14)\n",
      "\n",
      "Label distribution (>50K proportion):\n",
      "  Training set: 24.89%\n",
      "  Validation set: 24.90%\n",
      "  Test set: 24.57%\n",
      "============================================================\n",
      "\n",
      "C5.0 can use directly:\n",
      "  Training set: (24129, 14)\n",
      "  Validation set: (6033, 14)\n",
      "  Test set: (15060, 14)\n",
      "\n",
      "[Feature Information]\n",
      "------------------------------------------------------------\n",
      "Total features: 14\n",
      "Continuous features: ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
      "Categorical features: ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
      "\n",
      "============================================================\n",
      "✓ All examples completed\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, LabelEncoder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class UnifiedDataPreprocessor:\n",
    "    \"\"\"Handles unified data preprocessing for decision tree models.\"\"\"\n",
    "\n",
    "    COLUMNS = [\n",
    "        \"age\",\n",
    "        \"workclass\",\n",
    "        \"fnlwgt\",\n",
    "        \"education\",\n",
    "        \"education_num\",\n",
    "        \"marital_status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"capital_gain\",\n",
    "        \"capital_loss\",\n",
    "        \"hours_per_week\",\n",
    "        \"native_country\",\n",
    "        \"income\",\n",
    "    ]\n",
    "\n",
    "    CONTINUOUS_FEATURES = [\n",
    "        \"age\",\n",
    "        \"fnlwgt\",\n",
    "        \"education_num\",\n",
    "        \"capital_gain\",\n",
    "        \"capital_loss\",\n",
    "        \"hours_per_week\",\n",
    "    ]\n",
    "\n",
    "    CATEGORICAL_FEATURES = [\n",
    "        \"workclass\",\n",
    "        \"education\",\n",
    "        \"marital_status\",\n",
    "        \"occupation\",\n",
    "        \"relationship\",\n",
    "        \"race\",\n",
    "        \"sex\",\n",
    "        \"native_country\",\n",
    "    ]\n",
    "\n",
    "    def __init__(self, data_dir=\"../data\"):\n",
    "        \"\"\"Initializes the preprocessor with the data directory.\n",
    "\n",
    "        Args:\n",
    "            data_dir (str): Path to the directory containing data files.\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If training or test data files are not found.\n",
    "        \"\"\"\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.train_path = self.data_dir / \"adult.data\"\n",
    "        self.test_path = self.data_dir / \"adult.test\"\n",
    "        self.label_encoders = {}\n",
    "        self.discretizer = None\n",
    "\n",
    "        if not self.train_path.exists():\n",
    "            raise FileNotFoundError(f\"Training data file not found: {self.train_path}\")\n",
    "        if not self.test_path.exists():\n",
    "            raise FileNotFoundError(f\"Test data file not found: {self.test_path}\")\n",
    "\n",
    "\n",
    "    def load_raw_data(self, verbose=True):\n",
    "        \"\"\"Loads raw training and test data.\n",
    "\n",
    "        Args:\n",
    "            verbose (bool): If True, prints loading information.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (train_df, test_df) containing raw dataframes.\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"=\" * 60)\n",
    "            print(\"Loading raw data\")\n",
    "            print(\"=\" * 60)\n",
    "\n",
    "        train_df = pd.read_csv(\n",
    "            self.train_path, names=self.COLUMNS, na_values=\" ?\", skipinitialspace=True\n",
    "        )\n",
    "\n",
    "        test_df = pd.read_csv(\n",
    "            self.test_path,\n",
    "            names=self.COLUMNS,\n",
    "            na_values=\" ?\",\n",
    "            skiprows=1,\n",
    "            skipinitialspace=True,\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Training data shape: {train_df.shape}\")\n",
    "            print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "        return train_df, test_df\n",
    "\n",
    "\n",
    "    def clean_data(self, train_df, test_df, verbose=True):\n",
    "        \"\"\"Cleans training and test data by handling missing values and standardizing labels.\n",
    "\n",
    "        Args:\n",
    "            train_df (pd.DataFrame): Training dataframe.\n",
    "            test_df (pd.DataFrame): Test dataframe.\n",
    "            verbose (bool): If True, prints cleaning information.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (train_df, test_df) containing cleaned dataframes.\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"\\nCleaning data...\")\n",
    "\n",
    "        train_before = len(train_df)\n",
    "        test_before = len(test_df)\n",
    "\n",
    "        train_df = train_df.replace([\" ?\", \" ? \", \"?\"], np.nan)\n",
    "        test_df = test_df.replace([\" ?\", \" ? \", \"?\"], np.nan)\n",
    "\n",
    "        test_df[\"income\"] = test_df[\"income\"].str.replace(\".\", \"\", regex=False)\n",
    "\n",
    "        for df in [train_df, test_df]:\n",
    "            df[\"income\"] = df[\"income\"].str.strip()\n",
    "\n",
    "        train_df = train_df.dropna().reset_index(drop=True)\n",
    "        test_df = test_df.dropna().reset_index(drop=True)\n",
    "\n",
    "        valid_labels = [\"<=50K\", \">50K\"]\n",
    "        train_df = train_df[train_df[\"income\"].isin(valid_labels)].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        test_df = test_df[test_df[\"income\"].isin(valid_labels)].reset_index(drop=True)\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Training data: {train_before} → {len(train_df)} \"\n",
    "                f\"(removed {train_before - len(train_df)} rows)\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Test data: {test_before} → {len(test_df)} \"\n",
    "                f\"(removed {test_before - len(test_df)} rows)\"\n",
    "            )\n",
    "\n",
    "        return train_df, test_df\n",
    "\n",
    "\n",
    "    def encode_categorical(self, train_df, test_df, verbose=True):\n",
    "        \"\"\"Encodes categorical features using LabelEncoder.\n",
    "\n",
    "        Args:\n",
    "            train_df (pd.DataFrame): Training dataframe.\n",
    "            test_df (pd.DataFrame): Test dataframe.\n",
    "            verbose (bool): If True, prints encoding information.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (train_df, test_df) containing encoded dataframes.\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"\\nEncoding categorical features...\")\n",
    "\n",
    "        train_df = train_df.copy()\n",
    "        test_df = test_df.copy()\n",
    "\n",
    "        for feature in self.CATEGORICAL_FEATURES:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(train_df[feature].astype(str))\n",
    "            train_df[feature] = le.transform(train_df[feature].astype(str))\n",
    "\n",
    "            test_values = test_df[feature].astype(str)\n",
    "            unseen_mask = ~test_values.isin(le.classes_)\n",
    "\n",
    "            if unseen_mask.any():\n",
    "                mode_class = train_df[feature].mode()[0]\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        f\"  {feature}: Found {unseen_mask.sum()} unseen categories, \"\n",
    "                        f\"replaced with mode {mode_class}\"\n",
    "                    )\n",
    "                test_values[unseen_mask] = le.classes_[mode_class]\n",
    "\n",
    "            test_df[feature] = le.transform(test_values)\n",
    "            self.label_encoders[feature] = le\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"✓ Encoding complete for {len(self.CATEGORICAL_FEATURES)} categorical features\")\n",
    "\n",
    "        return train_df, test_df\n",
    "\n",
    "\n",
    "    def get_processed_data(\n",
    "        self,\n",
    "        discretize=False,\n",
    "        n_bins=10,\n",
    "        validation_split=0.0,\n",
    "        random_state=42,\n",
    "        verbose=True,\n",
    "    ):\n",
    "        \"\"\"Processes data and prepares it for model training.\n",
    "\n",
    "        Args:\n",
    "            discretize (bool): If True, discretizes continuous features.\n",
    "            n_bins (int): Number of bins for discretization.\n",
    "            validation_split (float): Proportion of training data to use for validation.\n",
    "            random_state (int): Random seed for reproducibility.\n",
    "            verbose (bool): If True, prints processing information.\n",
    "\n",
    "        Returns:\n",
    "            tuple: If validation_split > 0, returns (X_train, X_val, X_test, y_train, y_val, y_test).\n",
    "                   Otherwise, returns (X_train, X_test, y_train, y_test).\n",
    "        \"\"\"\n",
    "        train_df, test_df = self.load_raw_data(verbose)\n",
    "        train_df, test_df = self.clean_data(train_df, test_df, verbose)\n",
    "        train_df, test_df = self.encode_categorical(train_df, test_df, verbose)\n",
    "\n",
    "        if discretize:\n",
    "            train_df, test_df = self._discretize_continuous(train_df, test_df, n_bins, verbose)\n",
    "\n",
    "        feature_cols = self.CONTINUOUS_FEATURES + self.CATEGORICAL_FEATURES\n",
    "        X_train_full = train_df[feature_cols].values\n",
    "        y_train_full = (train_df[\"income\"] == \">50K\").astype(int).values\n",
    "        X_test = test_df[feature_cols].values\n",
    "        y_test = (test_df[\"income\"] == \">50K\").astype(int).values\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(\"Data preparation complete\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"Number of features: {len(feature_cols)}\")\n",
    "            print(f\"  - Continuous features: {len(self.CONTINUOUS_FEATURES)}\")\n",
    "            print(f\"  - Categorical features: {len(self.CATEGORICAL_FEATURES)}\")\n",
    "            print(f\"Discretized: {discretize}\")\n",
    "\n",
    "        if validation_split > 0:\n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                X_train_full,\n",
    "                y_train_full,\n",
    "                test_size=validation_split,\n",
    "                random_state=random_state,\n",
    "                stratify=y_train_full,\n",
    "            )\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"\\nData split:\")\n",
    "                print(f\"  Training set: {X_train.shape}\")\n",
    "                print(f\"  Validation set: {X_val.shape}\")\n",
    "                print(f\"  Test set: {X_test.shape}\")\n",
    "                print(f\"\\nLabel distribution (>50K proportion):\")\n",
    "                print(f\"  Training set: {y_train.mean():.2%}\")\n",
    "                print(f\"  Validation set: {y_val.mean():.2%}\")\n",
    "                print(f\"  Test set: {y_test.mean():.2%}\")\n",
    "                print(f\"{'='*60}\\n\")\n",
    "\n",
    "            return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(f\"\\nData shapes:\")\n",
    "                print(f\"  Training set: {X_train_full.shape}\")\n",
    "                print(f\"  Test set: {X_test.shape}\")\n",
    "                print(f\"\\nLabel distribution (>50K proportion):\")\n",
    "                print(f\"  Training set: {y_train_full.mean():.2%}\")\n",
    "                print(f\"  Test set: {y_test.mean():.2%}\")\n",
    "                print(f\"{'='*60}\\n\")\n",
    "\n",
    "            return X_train_full, X_test, y_train_full, y_test\n",
    "\n",
    "\n",
    "    def _discretize_continuous(self, train_df, test_df, n_bins, verbose):\n",
    "        \"\"\"Discretizes continuous features.\n",
    "\n",
    "        Args:\n",
    "            train_df (pd.DataFrame): Training dataframe.\n",
    "            test_df (pd.DataFrame): Test dataframe.\n",
    "            n_bins (int): Number of bins for discretization.\n",
    "            verbose (bool): If True, prints discretization information.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (train_df, test_df) containing discretized dataframes.\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(f\"\\nDiscretizing continuous features (n_bins={n_bins})...\")\n",
    "\n",
    "        train_df = train_df.copy()\n",
    "        test_df = test_df.copy()\n",
    "\n",
    "        self.discretizer = KBinsDiscretizer(\n",
    "            n_bins=n_bins, encode=\"ordinal\", strategy=\"quantile\", subsample=None\n",
    "        )\n",
    "\n",
    "        train_continuous = train_df[self.CONTINUOUS_FEATURES].values\n",
    "        test_continuous = test_df[self.CONTINUOUS_FEATURES].values\n",
    "\n",
    "        train_discretized = self.discretizer.fit_transform(train_continuous)\n",
    "        test_discretized = self.discretizer.transform(test_continuous)\n",
    "\n",
    "        for i, col in enumerate(self.CONTINUOUS_FEATURES):\n",
    "            train_df[col] = train_discretized[:, i].astype(int)\n",
    "            test_df[col] = test_discretized[:, i].astype(int)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"✓ Discretization complete, each feature divided into {n_bins} bins\")\n",
    "\n",
    "        return train_df, test_df\n",
    "\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        \"\"\"Returns the list of feature names.\n",
    "\n",
    "        Returns:\n",
    "            list: List of feature names.\n",
    "        \"\"\"\n",
    "        return self.CONTINUOUS_FEATURES + self.CATEGORICAL_FEATURES\n",
    "\n",
    "\n",
    "    def get_feature_info(self):\n",
    "        \"\"\"Returns detailed information about features.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary containing feature information.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"all_features\": self.get_feature_names(),\n",
    "            \"continuous\": self.CONTINUOUS_FEATURES,\n",
    "            \"categorical\": self.CATEGORICAL_FEATURES,\n",
    "            \"n_features\": len(self.CONTINUOUS_FEATURES) + len(self.CATEGORICAL_FEATURES),\n",
    "        }\n",
    "\n",
    "\n",
    "def example_usage():\n",
    "    \"\"\"Demonstrates usage of the UnifiedDataPreprocessor.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Unified Data Preprocessor Usage Example\")\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "    preprocessor = UnifiedDataPreprocessor(data_dir=\"../data\")\n",
    "\n",
    "    print(\"\\n[Example 1] CART model usage (no discretization, no validation set)\")\n",
    "    print(\"-\" * 60)\n",
    "    X_train, X_test, y_train, y_test = preprocessor.get_processed_data(\n",
    "        discretize=False, validation_split=0.0, verbose=True\n",
    "    )\n",
    "    print(f\"CART can use directly:\")\n",
    "    print(f\"  X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"  X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "    print(\"\\n[Example 2] C4.5 model usage (no discretization, with validation set)\")\n",
    "    print(\"-\" * 60)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = preprocessor.get_processed_data(\n",
    "        discretize=False, validation_split=0.1, random_state=42, verbose=True\n",
    "    )\n",
    "    print(f\"C4.5 can use directly:\")\n",
    "    print(f\"  Training set: {X_train.shape}\")\n",
    "    print(f\"  Validation set: {X_val.shape}\")\n",
    "    print(f\"  Test set: {X_test.shape}\")\n",
    "\n",
    "    print(\"\\n[Example 3] ID3 model usage (with discretization, with validation set)\")\n",
    "    print(\"-\" * 60)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = preprocessor.get_processed_data(\n",
    "        discretize=True, n_bins=10, validation_split=0.2, random_state=42, verbose=True\n",
    "    )\n",
    "    print(f\"ID3 can use directly:\")\n",
    "    print(f\"  Training set: {X_train.shape}\")\n",
    "    print(f\"  Validation set: {X_val.shape}\")\n",
    "    print(f\"  Test set: {X_test.shape}\")\n",
    "\n",
    "    print(\"\\n[Example 4] C5.0 model usage (with discretization, with validation set)\")\n",
    "    print(\"-\" * 60)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = preprocessor.get_processed_data(\n",
    "        discretize=True, n_bins=10, validation_split=0.2, random_state=42, verbose=True\n",
    "    )\n",
    "    print(f\"C5.0 can use directly:\")\n",
    "    print(f\"  Training set: {X_train.shape}\")\n",
    "    print(f\"  Validation set: {X_val.shape}\")\n",
    "    print(f\"  Test set: {X_test.shape}\")\n",
    "\n",
    "    print(\"\\n[Feature Information]\")\n",
    "    print(\"-\" * 60)\n",
    "    feature_info = preprocessor.get_feature_info()\n",
    "    print(f\"Total features: {feature_info['n_features']}\")\n",
    "    print(f\"Continuous features: {feature_info['continuous']}\")\n",
    "    print(f\"Categorical features: {feature_info['categorical']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✓ All examples completed\")\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "\n",
    "def get_data_for_cart():\n",
    "    \"\"\"Fetches data for CART model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_train, X_test, y_train, y_test) for CART model.\n",
    "    \"\"\"\n",
    "    preprocessor = UnifiedDataPreprocessor()\n",
    "    return preprocessor.get_processed_data(discretize=False, validation_split=0.0)\n",
    "\n",
    "\n",
    "def get_data_for_c45():\n",
    "    \"\"\"Fetches data for C4.5 model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_train, X_val, X_test, y_train, y_val, y_test) for C4.5 model.\n",
    "    \"\"\"\n",
    "    preprocessor = UnifiedDataPreprocessor()\n",
    "    return preprocessor.get_processed_data(\n",
    "        discretize=False, validation_split=0.1, random_state=42\n",
    "    )\n",
    "\n",
    "\n",
    "def get_data_for_id3():\n",
    "    \"\"\"Fetches data for ID3 model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_train, X_val, X_test, y_train, y_val, y_test) for ID3 model.\n",
    "    \"\"\"\n",
    "    preprocessor = UnifiedDataPreprocessor()\n",
    "    return preprocessor.get_processed_data(\n",
    "        discretize=True, n_bins=10, validation_split=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "\n",
    "def get_data_for_c50():\n",
    "    \"\"\"Fetches data for C5.0 model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_train, X_val, X_test, y_train, y_val, y_test) for C5.0 model.\n",
    "    \"\"\"\n",
    "    preprocessor = UnifiedDataPreprocessor()\n",
    "    return preprocessor.get_processed_data(\n",
    "        discretize=True, n_bins=10, validation_split=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    example_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
